{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                                                            #\n",
    "#    Mark Hoogendoorn and Burkhardt Funk (2017)              #\n",
    "#    Machine Learning for the Quantified Self                #\n",
    "#    Springer                                                #\n",
    "#    Chapter 5                                               #\n",
    "#                                                            #\n",
    "##############################################################\n",
    "\n",
    "from Chapter5.DistanceMetrics import InstanceDistanceMetrics\n",
    "from Chapter5.DistanceMetrics import PersonDistanceMetricsNoOrdering\n",
    "from Chapter5.DistanceMetrics import PersonDistanceMetricsOrdering\n",
    "from Chapter5.Clustering import NonHierarchicalClustering\n",
    "from Chapter5.Clustering import HierarchicalClustering\n",
    "import util.util as util\n",
    "from util.VisualizeDataset import VisualizeDataset\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, we set our program constants, read the input file and initialize a visualization object.\n",
    "DATA_PATH = Path('./intermediate_datafiles/')\n",
    "DATASET_FNAME = 'chapter4_result.csv'\n",
    "RESULT_FNAME = 'chapter5_result.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = pd.read_csv(DATA_PATH / DATASET_FNAME, index_col=0)\n",
    "    dataset = dataset[:14780]\n",
    "    dataset.index = pd.to_datetime(dataset.index)\n",
    "except IOError as e:\n",
    "    print('File not found, try to run previous crowdsignals scripts first!')\n",
    "    raise e\n",
    "    \n",
    "__file__ = 'Assignment_2_5.ipynb'\n",
    "DataViz = VisualizeDataset(__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_cluster = ['gyr_phone_x', 'gyr_phone_y', 'gyr_phone_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start by applying non-hierarchical clustering.\n",
    "clusteringNH = NonHierarchicalClustering()\n",
    "\n",
    "# Let us look at k-means first.\n",
    "k_values = range(2, 10)\n",
    "silhouette_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do some initial runs to determine the right number for k\n",
    "\n",
    "print('===== kmeans clustering =====')\n",
    "for k in k_values:\n",
    "    print(f'k = {k}')\n",
    "    dataset_cluster = clusteringNH.k_means_over_instances(copy.deepcopy(dataset), attributes_to_cluster, k, 'default', 20, 10)\n",
    "    silhouette_score = dataset_cluster['silhouette'].mean()\n",
    "    print(f'silhouette = {silhouette_score}')\n",
    "    silhouette_values.append(silhouette_score)\n",
    "\n",
    "DataViz.plot_xy(x=[k_values], y=[silhouette_values], xlabel='k', ylabel='silhouette score',\n",
    "                ylim=[0,1], line_styles=['b-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And run the knn with the highest silhouette score\n",
    "\n",
    "# k = 6 # todo: replaced with np.argmax call over silhouette scores\n",
    "k = k_values[np.argmax(silhouette_values)]\n",
    "print(f'Highest K-Means silhouette score: k = {k}')\n",
    "\n",
    "dataset_knn = clusteringNH.k_means_over_instances(copy.deepcopy(dataset), attributes_to_cluster, k, 'default', 50, 50)\n",
    "DataViz.plot_clusters_3d(dataset_knn, attributes_to_cluster, 'cluster', ['label'])\n",
    "DataViz.plot_silhouette(dataset_knn, 'cluster', 'silhouette')\n",
    "util.print_latex_statistics_clusters(dataset_knn, 'cluster', attributes_to_cluster, 'label')\n",
    "del dataset_knn['silhouette']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(2, 10)\n",
    "silhouette_values = []\n",
    "\n",
    "# Do some initial runs to determine the right number for k\n",
    "\n",
    "print('===== k medoids clustering =====')\n",
    "for k in k_values:\n",
    "    print(f'k = {k}')\n",
    "    dataset_cluster = clusteringNH.k_medoids_over_instances(copy.deepcopy(dataset), attributes_to_cluster, k, 'default', 20, n_inits=10)\n",
    "    silhouette_score = dataset_cluster['silhouette'].mean()\n",
    "    print(f'silhouette = {silhouette_score}')\n",
    "    silhouette_values.append(silhouette_score)\n",
    "\n",
    "DataViz.plot_xy(x=[k_values], y=[silhouette_values], xlabel='k', ylabel='silhouette score',\n",
    "                ylim=[0,1], line_styles=['b-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And run k medoids with the highest silhouette score\n",
    "\n",
    "# k = 6 # todo: replaced with np.argmax call over silhouette scores\n",
    "k = k_values[np.argmax(silhouette_values)]\n",
    "print(f'Highest K-Medoids silhouette score: k = {k}')\n",
    "\n",
    "dataset_kmed = clusteringNH.k_medoids_over_instances(copy.deepcopy(dataset), attributes_to_cluster, k, 'default', 20, n_inits=50)\n",
    "DataViz.plot_clusters_3d(dataset_kmed, attributes_to_cluster, 'cluster', ['label'])\n",
    "DataViz.plot_silhouette(dataset_kmed, 'cluster', 'silhouette')\n",
    "util.print_latex_statistics_clusters(dataset_kmed, 'cluster', attributes_to_cluster, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the hierarchical clustering is the last one we try\n",
    "\n",
    "clusteringH = HierarchicalClustering()\n",
    "\n",
    "k_values = range(2, 10)\n",
    "silhouette_values = []\n",
    "\n",
    "# Do some initial runs to determine the right number for the maximum number of clusters.\n",
    "\n",
    "print('===== agglomerative clustering =====')\n",
    "for k in k_values:\n",
    "    print(f'k = {k}')\n",
    "    dataset_cluster, l = clusteringH.agglomerative_over_instances(copy.deepcopy(dataset), attributes_to_cluster, k, 'euclidean', use_prev_linkage=True, link_function='ward')\n",
    "    silhouette_score = dataset_cluster['silhouette'].mean()\n",
    "    print(f'silhouette = {silhouette_score}')\n",
    "    silhouette_values.append(silhouette_score)\n",
    "    if k == k_values[0]:\n",
    "        DataViz.plot_dendrogram(dataset_cluster, l)\n",
    "\n",
    "DataViz.plot_xy(x=[k_values], y=[silhouette_values], xlabel='k', ylabel='silhouette score',\n",
    "                ylim=[0,1], line_styles=['b-'])\n",
    "\n",
    "# And we select the outcome dataset of the knn clustering....\n",
    "\n",
    "dataset_knn.to_csv(DATA_PATH / RESULT_FNAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
